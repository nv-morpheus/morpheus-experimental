{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e212b0",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "First, let's perform some basic installation and imports."
   ]
  },
  {
   "cell_type": "code",
   "id": "949ce4c2",
   "metadata": {},
   "source": [
    "%%capture \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "! pip install ipywidgets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7853252a",
   "metadata": {},
   "source": [
    "from src.preprocess import NetflowPreprocessor\n",
    "from src.guided_gae_model import GATEncoderWithEdgeAttr, GlobalEdgeEmbedding, DecoderWithGlobalEdge, GAEWithGlobalEdge\n",
    "import cudf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "669e6d63-6e30-4c17-8749-c89680735661",
   "metadata": {},
   "source": [
    "import torch \n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60a71e0e",
   "metadata": {},
   "source": "Let's also look at what a sample of the netflow data we'll be using looks like. Please note that your data must follow the `NF-CICIDS 2018` data format to use the rest of the dataset as is. If your schema changes, please modify the code below to account for it, including parameters for the `NetflowPreprocessor`."
  },
  {
   "cell_type": "code",
   "id": "9c9223eb",
   "metadata": {},
   "source": [
    "## Load your train data and test data here into CuDF dataframes.\n",
    "## You can use methods like `cudf.read_parquet` or `cudf.read_csv`\n",
    "\n",
    "## Save some sample test data for the morpheus pipeline\n",
    "## test_data.sample(n=1000).to_parquet('artifacts/sample_data.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "780db276",
   "metadata": {},
   "source": [
    "## Step 1: Create Data Loaders for Graphs with Benign Training Data\n",
    "\n",
    "This notebook is based on Netflow data from the Canadian Institue of Cybersecurity's CIC-IDS-2017 dataset. The data is collected across 5 working days (Monday-Friday) with Monday being all benign traffic, and the rest of the days containing mixed anomalous and benign traffic. \n",
    "\n",
    "In this example, we'll use Monday's benign Netflow to generate training examples. "
   ]
  },
  {
   "cell_type": "code",
   "id": "2799ac7a",
   "metadata": {},
   "source": [
    "# The first time this is run could take a few minutes \n",
    "processor = NetflowPreprocessor(\n",
    "    train_data.head(n=1_000_000) if len(train_data) > 1_000_000 else train_data,\n",
    "    edge_columns = ['IN_BYTES', 'OUT_BYTES', 'FLOW_DURATION_MILLISECONDS'],\n",
    "    node_dim = 32,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29a1b819",
   "metadata": {},
   "source": [
    "Now that the preprocessor has been initialized, we can create training examples. We'll do this by splitting the netflow into `window_size`  long windows, with a step size of `step_size`. For each window, we'll create a directed graph containing the node properaties and edge properties, along with a label on every edge. Each of these will be a training example. The labels are irrelevant during training as this is a self-supervised problem.\n",
    "\n",
    "In this case, all edge labels will be `0` because all connections are benign. All features will also be normalized using a CuML `StandardScaler`. \n",
    "\n",
    "Note that you will require a GPU to run these steps. Furthermore, you can also browse the implementation in the `src/preprocess.py` file."
   ]
  },
  {
   "cell_type": "code",
   "id": "b30d000c",
   "metadata": {},
   "source": [
    "benign_graphs, benign_ip_map, benign_data_windows = processor.construct_graph_list(window_size=1000, step_size=1000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3854560",
   "metadata": {},
   "source": [
    "Next, we'll split the graphs into training and validation splits, and construct PyTroch Geometric data loaders. "
   ]
  },
  {
   "cell_type": "code",
   "id": "6336ad92",
   "metadata": {},
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "def split_data(data_list, train_ratio=0.8):\n",
    "    train_size = int(len(data_list) * train_ratio)\n",
    "    test_size = len(data_list) - train_size\n",
    "    train_dataset, test_dataset = random_split(data_list, [train_size, test_size])\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Assume benging_graphs is already created as shown previously\n",
    "train_dataset, test_dataset = split_data(benign_graphs, train_ratio=0.8)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "# You can also save the scaler for use in a Morpheus pipeline using the following line of code\n",
    "# processor.save_scaler('artifacts/sample_edge_scaler.pkl') # Modify path as required"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a78a244f",
   "metadata": {},
   "source": [
    "## Step 2: Construct Data Loaders for Malicious Test Data\n",
    "\n",
    "Now, we'll create a data loader with data containing both benign and attack data. In this case, the edge attributes will also contain a label so that we can evaluate model performance down the line. \n",
    "\n",
    "Here, we won't re-instantiate the `preprocessor` object because it has already been built and contains scalers fit on benign data. This is important because we'll want to scale the test data using the scaler built on training data to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "id": "2ae82f5f",
   "metadata": {},
   "source": [
    "attack_graphs, attack_ip_map, attack_data_windows = processor.construct_graph_list(\n",
    "    df = test_data,\n",
    "    window_size = 1000,\n",
    "    step_size=1000\n",
    ")\n",
    "\n",
    "attack_loader = DataLoader(attack_graphs, batch_size=256, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f42f412",
   "metadata": {},
   "source": [
    "## Step 3: Training the Graph Autoencoder (GAE)\n",
    "\n",
    "In this section, we'll train a GAE to reconstruct the adjacency matrix of an input graph using the graph's `topology`, `node properties`, and `edge properties`. The goal of the GAE training objective will be to create an adjancecy matrix with each edge being the probability of existence of a certain edge. \n",
    "\n",
    " We perform negative edge sampling on the input graphs: This essentially means that we'll also add random, 'noisy' edges to the input graph durining training and ensure that the model *does not* reconstruct those\n",
    "\n",
    "\n",
    "While evaluating the model on the test set, we'll measure for overfitting by monitoring the area under the ROC curve, and the average precision. "
   ]
  },
  {
   "cell_type": "code",
   "id": "c3694ae8",
   "metadata": {},
   "source": [
    "# train_test.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "def train(model, optimizer, data_loader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in tqdm(data_loader, desc='Training'):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Encode\n",
    "        z = model.encode(data.x, data.edge_index, data.edge_attr[:, :-1])\n",
    "        # Positive edges\n",
    "        pos_edge_index = data.edge_index\n",
    "        pos_edge_attr = data.edge_attr[:, :-1]\n",
    "\n",
    "        # Negative edges (sampled for negative examples)\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=pos_edge_index,\n",
    "            num_nodes=data.num_nodes,\n",
    "            num_neg_samples=pos_edge_index.size(1),\n",
    "            method='sparse'\n",
    "        )\n",
    "\n",
    "        # For negative edges, we need to create dummy edge attributes (e.g., zeros)\n",
    "        neg_edge_attr = torch.zeros(neg_edge_index.size(1), data.edge_attr.size(1)-1).to(device)\n",
    "\n",
    "        # Decode positive edges\n",
    "        pos_pred = model.decode(z, pos_edge_index, pos_edge_attr, data.batch)\n",
    "\n",
    "        # Decode negative edges\n",
    "        neg_pred = model.decode(z, neg_edge_index, neg_edge_attr, data.batch)\n",
    "\n",
    "        # Create labels\n",
    "        pos_label = torch.ones(pos_pred.size()).to(device)\n",
    "        neg_label = torch.zeros(neg_pred.size()).to(device)\n",
    "\n",
    "        # Concatenate predictions and labels\n",
    "        preds = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "        labels = torch.cat([pos_label, neg_label], dim=0)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.binary_cross_entropy(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader, desc='Testing'):\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Encode\n",
    "            z = model.encode(data.x, data.edge_index, data.edge_attr[:, :-1])\n",
    "\n",
    "            # Positive edges\n",
    "            pos_edge_index = data.edge_index\n",
    "            pos_edge_attr = data.edge_attr[:, :-1]\n",
    "\n",
    "            # Negative edges (sampled for negative examples)\n",
    "            neg_edge_index = negative_sampling(\n",
    "                edge_index=pos_edge_index,\n",
    "                num_nodes=data.num_nodes,\n",
    "                num_neg_samples=pos_edge_index.size(1),\n",
    "                method='sparse'\n",
    "            )\n",
    "\n",
    "            # For negative edges, we need to create dummy edge attributes (e.g., zeros)\n",
    "            neg_edge_attr = torch.zeros(neg_edge_index.size(1), data.edge_attr.size(1)-1).to(device)\n",
    "\n",
    "            # Decode positive edges\n",
    "            pos_pred = model.decode(z, pos_edge_index, pos_edge_attr, data.batch)\n",
    "            pos_label = torch.ones(pos_pred.size()).to(device)\n",
    "\n",
    "            # Decode negative edges\n",
    "            neg_pred = model.decode(z, neg_edge_index, neg_edge_attr, data.batch)\n",
    "            neg_label = torch.zeros(neg_pred.size()).to(device)\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            preds.append(torch.cat([pos_pred, neg_pred], dim=0).cpu())\n",
    "            labels.append(torch.cat([pos_label, neg_label], dim=0).cpu())\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "\n",
    "    # Compute ROC-AUC and Average Precision\n",
    "    roc_auc = roc_auc_score(labels, preds)\n",
    "    avg_precision = average_precision_score(labels, preds)\n",
    "\n",
    "    return roc_auc, avg_precision\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "375d8159",
   "metadata": {},
   "source": "Let's instatiate the model and associated objects. We can also take a look at what the Guided GAE architecture looks like. The key daddition to this model is that it also allows the VGAE to use graph-wide edge properties to guide the reconstruction of the adjacency matrix."
  },
  {
   "cell_type": "code",
   "id": "80da6b9e",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "in_channels = benign_graphs[0].x.size(1)\n",
    "hidden_channels = 256\n",
    "edge_attr_dim = 3\n",
    "global_emb_dim = 128\n",
    "\n",
    "encoder = GATEncoderWithEdgeAttr(in_channels, hidden_channels, edge_attr_dim)\n",
    "global_edge_embedding = GlobalEdgeEmbedding(edge_attr_dim, global_emb_dim)\n",
    "decoder = DecoderWithGlobalEdge(hidden_channels, edge_attr_dim, global_emb_dim)\n",
    "\n",
    "model = GAEWithGlobalEdge(encoder, decoder, global_edge_embedding).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.003)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)\n",
    "\n",
    "model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5a45635",
   "metadata": {},
   "source": [
    "We notice that the GAE has encoder and decoder blocks. \n",
    "\n",
    "The model architecture is composed of an encoder, a global edge embedding module, and a decoder, all integrated to form a Graph Autoencoder (GAE)-like framework that incorporates global edge-level context.\n",
    "\n",
    "The encoder, defined by `GATEncoderWithEdgeAttr`, takes node and edge attributes and transforms them into latent node embeddings. It first applies a `GATv2Conv(32, 256, heads=4)`, which uses multi-headed attention (4 heads) to produce a total of `1024` features from `32` input features per node (4 heads × 256 features each). Unlike a standard GAT layer, this variant can incorporate edge attributes into the attention mechanism, allowing the attention weights to depend on both node and edge-level information. The resulting embeddings are normalized with a `BatchNorm1d(1024)` operation to stabilize training. Next, a `GraphUNet(1024, 256, 256, depth=3, pool_ratios=[0.5, 0.5, 0.5])` is applied, providing a hierarchy of pooling and unpooling steps to capture multi-scale graph structure and produce refined 256-dimensional embeddings. This multi-resolution representation helps the encoder capture both local connectivity patterns and more global topological features.\n",
    "\n",
    "A `GlobalEdgeEmbedding` module provides a global context of edge information. This module takes a 3-dimensional global edge feature vector and processes it through a small MLP: a `Linear(3, 128)` layer, followed by a `ReLU` activation, and then another `Linear(128, 128)`. The output is a 128-dimensional global edge embedding that encapsulates global edge attributes, complementing the node-level embeddings by providing a holistic view of the entire graph’s edge structure.\n",
    "\n",
    "The decoder, implemented as `DecoderWithGlobalEdge`, integrates the node embeddings, edge embeddings, and global edge embedding to reconstruct or predict edges. The raw edge attributes (3-dimensional) are first mapped to 256 dimensions via `fc_edge` (`Linear(3,256)`). The global edge embedding (128-dimensional) is similarly expanded to 256 dimensions by `fc_global` (`Linear(128,256)`). The node embeddings, edge embeddings, and global edge embeddings are then combined to form a 768-dimensional vector (256 per component). The decoder processes this combined vector through `fc1` (`Linear(768,768)`), which can further refine the joint representation, and then `fc` (`Linear(768,1)`), which outputs a scalar value for each potential edge. This scalar can represent probabilities or scores for edge existence, thereby enabling the model to reconstruct the adjacency structure or predict edge properties.\n",
    "\n",
    "\n",
    "Now that we've instantiated the requisite pieces, we can run training for a few epochs. "
   ]
  },
  {
   "cell_type": "code",
   "id": "9a9bd2d1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Example training and testing loop\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    print(f'#############Epoch {epoch}###############')\n",
    "    train_loss = train(model, optimizer, train_loader, device)\n",
    "    auc, ap = test(model, test_loader, device)\n",
    "    scheduler.step()\n",
    "    print(f'AUC: {auc} AP: {ap} Loss: {train_loss}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "710eecf4-246f-45d3-b11f-99a0c9759a9b",
   "metadata": {},
   "source": "torch.save(model.state_dict(), \"artifacts/sample_weights.pth\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b5f24d18",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Model Performance on Attack Data\n",
    "\n",
    "In this final step, we aim to evaluate the performance of the trained model on previously unseen benign and attack data, which had been loaded into our `attack_loader` in prior steps. We'll evaluate `False Positive Rates (FPR)`, `True Positive Rates (TPR)`, and the `Confusion Matrix` for binary classification. In our example, anomalous edges have a label `1` and benign edges `0`. \n",
    "\n",
    "Recall that a VGAE outputs probilities of an edge occuring in the adjacency matrix. From there, anomaly detection is straightforward. We can threshold the liklihood of a given edge as belonging to a graph or not. Any edge with a low probability can be classified as anomalous.\n",
    "\n",
    "First, we'll define a function to compute the metrics given a data loader and model. "
   ]
  },
  {
   "cell_type": "code",
   "id": "e22486b4-5721-4fd4-abb7-beee1f5e62e0",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b998839",
   "metadata": {},
   "source": [
    "from cuml.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, balanced_accuracy_score\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Define the function to compute metrics\n",
    "def compute_metrics(data_loader, model, device, threshold=0.1):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader, desc='Inference examples'):\n",
    "            data = data.to(device)\n",
    "            z = model.encode(data.x, data.edge_index, data.edge_attr[:, :-1])\n",
    "            preds = model.decode(z, data.edge_index, data.edge_attr[:, :-1], data.batch)\n",
    "            # Likelihood of Not Belonging in Graph\n",
    "            all_preds.append(1 - cp.asarray(preds.float().cpu().numpy()))\n",
    "            all_labels.append(cp.asarray(data.edge_attr[:, -1].cpu().numpy()))\n",
    "    \n",
    "    all_preds = cp.concatenate(all_preds)\n",
    "    all_labels = cp.concatenate(all_labels)\n",
    "    \n",
    "    unique_values, counts = cp.unique(all_labels, return_counts=True)\n",
    "\n",
    "    print(f\"Unique values: {unique_values}\")\n",
    "    print(f\"Counts: {counts}\")\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(all_labels.get(), all_preds.get())\n",
    "    \n",
    "    roc_auc = roc_auc_score(all_labels.get(), all_preds.get())\n",
    "\n",
    "    del all_preds\n",
    "    del all_labels\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    youdens_j = tpr - fpr\n",
    "    idx = np.argmax(youdens_j)\n",
    "    best_threshold = thresholds[idx]\n",
    "    best_fpr = fpr[idx]\n",
    "    best_tpr = tpr[idx]\n",
    "\n",
    "    return roc_auc, best_fpr, best_tpr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b233df2e",
   "metadata": {},
   "source": [
    "Finally, we can compute metrics for the VGAE on mixed attack and benign data."
   ]
  },
  {
   "cell_type": "code",
   "id": "0ffc0cc6",
   "metadata": {},
   "source": [
    "compute_metrics(attack_loader, model, device, threshold=0.0015)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

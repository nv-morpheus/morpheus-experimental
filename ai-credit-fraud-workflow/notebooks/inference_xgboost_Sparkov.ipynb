{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook loads a pre-trained XGBoost model and runs inference on raw data\n",
    "__NOTE__: This XGBoost model does not leverage embeddings from the GNN (GraphSAGE) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "* Outline the steps to transform new raw data before feeding it into the model.\n",
    "* Simulate the use of the trained model on new data during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from cuml.metrics import confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score)\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path to the pre-trained XGBoost model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = '../data/Sparkov'\n",
    "model_root_dir = os.path.join(dataset_base_path, 'models')\n",
    "model_file_name = 'xgboost_model.json'\n",
    "xgb_model_path = os.path.join(model_root_dir, model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xgboost model for node classification\n",
    "loaded_bst = xgb.Booster()\n",
    "loaded_bst.load_model(xgb_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load column names and other global variable saved during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open(os.path.join(dataset_base_path, 'variables.json'), 'r') as json_file:\n",
    "    column_names = json.load(json_file)\n",
    "\n",
    "# Repopulate the variables in the global namespace\n",
    "globals().update(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Evaluate the XGBoost model on untransformed test data (saved in the preprocessing notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read untransformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)    \n",
    "path_to_untransformed_data = os.path.join(dataset_base_path, 'xgb', 'untransformed_test.csv')\n",
    "untransformed_df = pd.read_csv(path_to_untransformed_data)\n",
    "untransformed_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data transformer and transform the data using the loaded transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_base_path, 'preprocessor.pkl'),'rb') as f:\n",
    "    loaded_transformer = pickle.load(f)\n",
    "    transformed_data = loaded_transformer.transform(\n",
    "        untransformed_df.loc[:, untransformed_df.columns[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the model on the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor columns used for training\n",
    "numerical_predictors = [COL_AMOUNT, COL_SPEED, COL_AGE]\n",
    "nominal_predictors = [COL_CARD, COL_ZIP, COL_MCC, COL_MERCHANT, COL_JOB]\n",
    "\n",
    "predictor_columns = numerical_predictors + nominal_predictors\n",
    "\n",
    "target_column = [COL_FRAUD]\n",
    "\n",
    "# transformed column names\n",
    "columns_of_transformed_data = list(\n",
    "    map(lambda name: name.split('__')[1],\n",
    "        list(loaded_transformer.get_feature_names_out(predictor_columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    transformed_data, columns=columns_of_transformed_data)\n",
    "\n",
    "y = untransformed_df[untransformed_df.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_prob = loaded_bst.predict(xgb.DMatrix(data=X, label=y))\n",
    "\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute metrics to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_mat)\n",
    "\n",
    "# ROC AUC Score\n",
    "r_auc = roc_auc_score(y, y_pred_prob)\n",
    "print(f'ROC AUC Score: {r_auc:.4f}')\n",
    "\n",
    "# y = cupy.asnumpy(y)\n",
    "# Precision\n",
    "precision = precision_score(y, y_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y, y_pred)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Prediction on raw inputs\n",
    "* The purpose is to demonstrate the use of the model during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_file_path = os.path.join(dataset_base_path, 'xgb', 'example_transactions.csv')\n",
    "data = pd.read_csv(raw_file_path)\n",
    "data = data[data.columns[:-1]]\n",
    "original_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if the transactions have unknown users or merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the known merchants and (users, cards), i.e. the merchants and (users, cards) that are in training data\n",
    "known_merchants = set()\n",
    "known_cards = set()\n",
    "\n",
    "for enc in  loaded_transformer.named_transformers_['binary'].named_steps['binary'].ordinal_encoder.mapping:\n",
    "    if enc['col'] == COL_MERCHANT:\n",
    "        known_merchants = set(enc['mapping'].keys())\n",
    "    if enc['col'] == COL_CARD:\n",
    "        known_cards = set(enc['mapping'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is user, card already known\n",
    "data['Is_card_known'] = data[COL_CARD].map(lambda c: c in known_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is merchant already known\n",
    "data['Is_merchant_known'] = data[COL_MERCHANT].map(lambda m: m in known_merchants )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  From ('lat', 'long'), ('merchant_lat', 'merchant_long') and unix_time to compute transaction speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_df = pd.DataFrame()\n",
    "import math\n",
    "# Haversine formula function\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of Earth in km\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert degrees to radians\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    # Differences in coordinates\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Haversine formula\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "\n",
    "temp_df=  data[['unix_time', 'lat', 'long', 'merch_lat', 'merch_long']].copy()\n",
    "temp_df['tx_duration'] = temp_df['unix_time'].apply(lambda x: x/1e9)\n",
    "temp_df['distance_km'] = temp_df.apply(\n",
    "    lambda row: haversine(row['lat'], row['long'], row['merch_lat'], row['merch_long']), axis=1)\n",
    "\n",
    "data['speed'] =  (temp_df['distance_km']/temp_df['tx_duration'])\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert 'dob' to 'age' w.r.t. a reference date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['dob'] = pd.to_datetime(data['dob'])\n",
    "one_nanosecond = np.timedelta64(1, 'ns')\n",
    "nanoseconds_in_year = 365.25 * 24 * 60 * 60 * 1e9\n",
    "reference_date =  pd.to_datetime('2024-10-30') \n",
    "data['age'] = data['dob'].apply(lambda dob: (reference_date - dob)/ one_nanosecond / nanoseconds_in_year )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set of predictor columns used for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_predictors = [COL_AMOUNT, COL_SPEED, COL_AGE]\n",
    "nominal_predictors = [COL_CARD, COL_ZIP, COL_MCC, COL_MERCHANT, COL_JOB]\n",
    "\n",
    "predictor_columns = numerical_predictors + nominal_predictors\n",
    "\n",
    "target_column = [COL_FRAUD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform input data using the pre-fitted data transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_base_path, 'preprocessor.pkl'),'rb') as f:\n",
    "    loaded_transformer = pickle.load(f)\n",
    "    transformed_data = loaded_transformer.transform(data[predictor_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data and predict if the transactions are fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.DataFrame(\n",
    "    transformed_data, columns=columns_of_transformed_data)\n",
    "\n",
    "# Predict transactions\n",
    "pred_probs = loaded_bst.predict(xgb.DMatrix(X))\n",
    "pred_labels = (pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# Name of the target column\n",
    "target_col_name = 'Is Fraud?'\n",
    "\n",
    "data[target_col_name] = pred_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the transactions have unknown (user, card) or merchant, mark it as fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[target_col_name] = data.apply(\n",
    "    lambda row: (row[target_col_name] == 1) or (row['Is_card_known'] == False) or (row['Is_merchant_known'] == False), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label the raw data as Fraud or Non-Fraud, based on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change 0 to No (non-Fraud) and 1 to Yes (Fraud)\n",
    "binary_to_text = { False: 'No', True : 'Yes'}\n",
    "data[target_col_name] = data[target_col_name].map(binary_to_text).astype('str')\n",
    "original_data[target_col_name] = data[target_col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions with predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copyright and License\n",
    "<hr/>\n",
    "Copyright (c) 2024, NVIDIA CORPORATION. All rights reserved.\n",
    "\n",
    "<br/>\n",
    "\n",
    " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " you may not use this file except in compliance with the License.\n",
    " You may obtain a copy of the License at\n",
    " \n",
    " http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    " Unless required by applicable law or agreed to in writing, software\n",
    " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " See the License for the specific language governing permissions and\n",
    " limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
